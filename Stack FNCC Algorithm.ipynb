{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOI Locator for uCT Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is effectively a simple adaptation of the typical fast normalised cross correlation algorithm (published by (]J. P. Lewis in 2005) from a single slice into a three dimensional stack. We have a series of stacks with a sedimenting material which we can work through in one of two ways. Either we can analyse the whole lot in a single shot using a nested for loop or simply go one stack at a time with a single loop. To run this script we need the scikit image `skimage` `io` submodule and the `match_template` function from the `feature` submodule. We also include `matplotlib` for debugging and good measure.`glob` is required for reading directories from the filesystem. \n",
    "\n",
    "To test the code we can apply the analysis back to the first stack and should get a regression coefficient $R = 1.0$.\n",
    "\n",
    "This script has been tested working on Python 3.6 on Arch Linux and Microsoft Windows 10 operating systems prior to publication with scikit-image 0.16.1\n",
    "\n",
    "TODO:\n",
    "\n",
    "-- Test with scikit-image 0.17.1 (05-2020).\n",
    "\n",
    "-- increase speed of analysis by defining a trigger threshold for the regression coefficient at which we exit the loop.\n",
    "\n",
    "-- Increase speed of analysis by predictive locating.\n",
    "\n",
    "-- Code for single shot approach detailed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.feature import match_template\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as no\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we typically reconstruct tomographic data into a 16-bit or 32-bit image series, I've lowered the precision here as all we are interested in is the internal morphology and a 16-bit precision is unnecessary and just eats disk space. If we want we can load a Zeiss txrm file using `tomopy` but I've not shown this here as it will require the file path and for loop to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = sorted(glob.glob(\"8-bit/*.tiff\"))\n",
    "# For tif, jpg, and png files respectively, a simple change.\n",
    "#stack = sorted(glob.glob(\"*.tif\"))\n",
    "#stack = sorted(glob.glob(\"8-bit/*.jpg\"))\n",
    "#stack = sorted(glob.glob(\"8-bit/*.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load a slice which represents our first VOI. This would normally be taken from the first scan, but there's nothing stopping you from taking from the last scan and working forwards. `VOI` is the  slice representative of the Volume of Interest. Again, change the file extension similarly to the above cell if required. I've not counted the number of slices here for abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOI_slice = \"VOISlice.tiff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we begin iterating through the stack. `interog_slice` is the slice in the stack we are interrogating at this point in the loop. We load each slice into this numpy array using imread from `skimage.io`. \n",
    "\n",
    "Note: It is possible here to load the entire stack into RAM and run through the whole thing in a single hit. This isn't necessarily any quicker if you're on an SSD from what I can tell. \n",
    "\n",
    "In `results` we store our maximum coefficient $R$ for each slice. $x$ and $y$ are written to columns 0 and 1, and $R$ to column 2. The $z$ value is the argument to the maximum for $R$, and then we can take $x$ and $y$ back from the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.empty((len(stack), 3))\n",
    "\n",
    "for ii in range(0, len(stack)):\n",
    "    # Load the interrogated slice (see above).\n",
    "    interog_slice = io.imread(stack[ii])\n",
    "    \n",
    "    # Run the match_template fast normalised cross correlation algorithm.\n",
    "    result = match_template(interog_slice, VOI_slice)\n",
    "    \n",
    "    # Convert the flat argmax into a tuple of xy values\n",
    "    ab = np.unravel_index(np.argmax(result), result.shape)\n",
    "    \n",
    "    # Write the x, y, and R results to the values array\n",
    "    values[ii,2] = np.max(result)\n",
    "    x,y = ab[::-1]\n",
    "    values[ii,0] = x\n",
    "    values[ii,1] = y\n",
    "    \n",
    "# The z location is the argument to the maximum in column 0 (see above)\n",
    "z = np.argmax(values[:,0])\n",
    "\n",
    "# Then x and y are the values at this maximum in columns 1 and 2\n",
    "x = values[z,1]\n",
    "y = values[z,2]\n",
    "\n",
    "# Finish with some nice output\n",
    "print(\"VOI Located at x = {}, y = {}, z = {}\".format(x,y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfinished and untested ... for the trigger threshold approach, try:\n",
    "\n",
    "If we hit a value that is greater than `trigger_threshond` we start watching for increasing $R$ values until the rate of increase becomes less than `trigger_delta` at which point $R$ is probably about to reduce as we drop through the stack and we can exit the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous R = 0\n",
    "trigger_delta = 0.1\n",
    "trigger = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See commented code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.empty((len(stack), 3))\n",
    "\n",
    "for ii in range(0, len(stack)):\n",
    "    # Load the interrogated slice (see above).\n",
    "    interog_slice = io.imread(stack[ii])\n",
    "    \n",
    "    # Run the match_template fast normalised cross correlation algorithm.\n",
    "    result = match_template(interog_slice, VOI_slice)\n",
    "    \n",
    "    # Convert the flat argmax into a tuple of xy values\n",
    "    ab = np.unravel_index(np.argmax(result), result.shape)\n",
    "    \n",
    "    # Write the x, y, and R results to the values array.\n",
    "    # This may seem like poor abstraction but it makes sense for readability...\n",
    "    R = np.max(result)\n",
    "    x,y = ab[::-1]\n",
    "    \n",
    "    values[ii,2] = R\n",
    "    values[ii,0] = x\n",
    "    values[ii,1] = y\n",
    "    \n",
    "    # Test R to see if it is above the trigger value\n",
    "    if (R > trigger):\n",
    "        # If the difference between the previous R value and this R value\n",
    "        # is greater than the delta value our numbers are still changing rapidly\n",
    "        # so set the previous_R value to R and continue the loop.\n",
    "        if ((R - previous_R) > trigger_delta)\n",
    "            previous_R = R\n",
    "        # The change in R has dropped below the triggering delta value,\n",
    "        # so we can break the loop and write the value to output.\n",
    "        elif ((R - previous_R < trigger_delta))\n",
    "            break;\n",
    "        \n",
    "# The z location is the argument to the maximum in column 0 (see above)\n",
    "z = np.argmax(values[:,0])\n",
    "\n",
    "# Then x and y are the values at this maximum in columns 1 and 2\n",
    "x = values[z,1]\n",
    "y = values[z,2]\n",
    "\n",
    "# Finish with some nice output\n",
    "print(\"VOI Located at x = {}, y = {}, z = {}\".format(x,y,z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
